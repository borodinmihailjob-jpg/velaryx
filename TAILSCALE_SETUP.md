# üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç: Tailscale + Auto-Fallback

–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π Ollama —á–µ—Ä–µ–∑ Tailscale Funnel —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º fallback –Ω–∞ –æ–±–ª–∞—á–Ω—ã–µ LLM.

## üìã –ß—Ç–æ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å

```
Telegram Bot ‚Üí FastAPI Backend ‚Üí [–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤]
                                   1. Ollama —á–µ—Ä–µ–∑ Tailscale (–±–µ—Å–ø–ª–∞—Ç–Ω–æ)
                                   2. OpenRouter free tier (–±–µ—Å–ø–ª–∞—Ç–Ω–æ)
                                   3. Gemini (–±–µ—Å–ø–ª–∞—Ç–Ω–æ, –ª–∏–º–∏—Ç—ã)
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚úÖ Mac online ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤–∞—à –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π Ollama
- ‚úÖ Mac offline –∏–ª–∏ tunnel down ‚Üí –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ OpenRouter
- ‚úÖ OpenRouter –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Üí fallback –Ω–∞ Gemini
- ‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –∑–∞–º–µ—á–∞–µ—Ç —Ä–∞–∑–Ω–∏—Ü—ã

---

## üéØ –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama Proxy (–Ω–∞ Mac)

```bash
# 1. –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
mkdir -p ~/ollama-proxy
cd ~/ollama-proxy

# 2. –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
cp ~/Documents/astrobot/ollama-proxy/main.py .
cp ~/Documents/astrobot/ollama-proxy/requirements.txt .

# 3. –°–æ–∑–¥–∞—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
python3 -m venv venv
source venv/bin/activate

# 4. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements.txt

# 5. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å proxy
python main.py
```

–û—Ç–∫—Ä–æ–π—Ç–µ http://localhost:8888/health - –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å `{"status":"healthy"}`

**–û—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ proxy (Ctrl+C) –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º.**

---

## üîê –®–∞–≥ 2: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Tailscale (–Ω–∞ Mac)

```bash
# 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Tailscale
brew install tailscale

# 2. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–∏—Å
sudo brew services start tailscale

# 3. –ê–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è (–æ—Ç–∫—Ä–æ–µ—Ç—Å—è –±—Ä–∞—É–∑–µ—Ä)
sudo tailscale up

# 4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å
tailscale status
```

---

## üåê –®–∞–≥ 3: –í–∫–ª—é—á–µ–Ω–∏–µ Tailscale Funnel

```bash
# 1. –ó–∞–ø—É—Å—Ç–∏—Ç—å proxy —Å–Ω–æ–≤–∞
cd ~/ollama-proxy
source venv/bin/activate
python main.py &

# 2. –í–∫–ª—é—á–∏—Ç—å –ø—É–±–ª–∏—á–Ω—ã–π –¥–æ—Å—Ç—É–ø —á–µ—Ä–µ–∑ Funnel
tailscale funnel 8888

# –í—ã –ø–æ–ª—É—á–∏—Ç–µ URL —Ç–∏–ø–∞:
# https://your-macbook.tail1234.ts.net

# 3. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç—Ç–æ—Ç URL - –æ–Ω –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –¥–ª—è backend!
echo "–ú–æ–π Tailscale URL:" > ~/ollama-proxy/tailscale-url.txt
tailscale funnel status | grep "https://" >> ~/ollama-proxy/tailscale-url.txt

# 4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç
curl https://your-macbook.tail1234.ts.net/health
```

**‚úÖ –ï—Å–ª–∏ –≤–µ—Ä–Ω—É–ª—Å—è `{"status":"healthy"}` - Funnel —Ä–∞–±–æ—Ç–∞–µ—Ç!**

---

## ‚öôÔ∏è –®–∞–≥ 4: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫–∞ (–Ω–∞ Mac)

```bash
# 1. –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å launchd plist
cp ~/Documents/astrobot/ollama-proxy/com.astrobot.ollama-proxy.plist \
   ~/Library/LaunchAgents/

# 2. –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–µ—Ä–≤–∏—Å
launchctl load ~/Library/LaunchAgents/com.astrobot.ollama-proxy.plist

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è
launchctl list | grep ollama-proxy

# 4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏
tail -f ~/ollama-proxy/proxy.log
```

**–¢–µ–ø–µ—Ä—å proxy –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å—Ç–∞—Ä—Ç–æ–≤–∞—Ç—å –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ Mac!**

---

## üîß –®–∞–≥ 5: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ AstroBot Backend

–û–±–Ω–æ–≤–∏—Ç–µ `.env` –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞:

```bash
# === LLM Configuration ===

# –í–∫–ª—é—á–∏—Ç—å auto-fallback
LLM_PROVIDER=auto

# Primary: Ollama —á–µ—Ä–µ–∑ Tailscale Funnel
OLLAMA_MODEL=qwen2.5:7b
OLLAMA_BASE_URL=https://your-macbook.tail1234.ts.net  # ‚¨ÖÔ∏è –í–ê–® URL!
OLLAMA_TIMEOUT_SECONDS=10  # –ë—ã—Å—Ç—Ä—ã–π timeout –¥–ª—è fallback

# Backup #1: OpenRouter (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏)
OPENROUTER_API_KEY=sk-or-v1-...  # ‚¨ÖÔ∏è –ü–æ–ª—É—á–∏—Ç—å –Ω–∞ https://openrouter.ai/keys
OPENROUTER_MODEL=deepseek/deepseek-r1-0528:free
OPENROUTER_TIMEOUT_SECONDS=30

# Backup #2: Gemini (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
GEMINI_API_KEY=...  # ‚¨ÖÔ∏è –ü–æ–ª—É—á–∏—Ç—å –Ω–∞ https://makersuite.google.com/app/apikey
GEMINI_MODEL=gemini-2.0-flash
```

### –ì–¥–µ –≤–∑—è—Ç—å API –∫–ª—é—á–∏ (–±–µ—Å–ø–ª–∞—Ç–Ω–æ):

**OpenRouter:**
1. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ https://openrouter.ai
2. –ü–æ–ª—É—á–∏—Ç—å –∫–ª—é—á: https://openrouter.ai/keys
3. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å privacy: https://openrouter.ai/settings/privacy
   - –í–∫–ª—é—á–∏—Ç—å: "Allow free models to use my data for training"

**Gemini (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):**
1. –ü–µ—Ä–µ–π—Ç–∏ –Ω–∞ https://makersuite.google.com/app/apikey
2. –°–æ–∑–¥–∞—Ç—å API key
3. –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –ª–∏–º–∏—Ç: 15 requests/minute

---

## üß™ –®–∞–≥ 6: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –¢–µ—Å—Ç 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ Ollama

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å backend
docker compose up --build

# –í –¥—Ä—É–≥–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ: —Å–¥–µ–ª–∞—Ç—å –∑–∞–ø—Ä–æ—Å
curl http://localhost:8000/v1/tarot/draw -X POST \
  -H "Content-Type: application/json" \
  -H "X-TG-USER-ID: 123" \
  -d '{
    "spread_type": "three_card",
    "question": "–¢–µ—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å"
  }'
```

**–ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –ª–æ–≥–∏ backend:**
```bash
docker compose logs api | grep LLM
```

–î–æ–ª–∂–Ω—ã —É–≤–∏–¥–µ—Ç—å:
```
LLM request | provider=auto (ollama‚Üíopenrouter‚Üígemini)
LLM success | provider=ollama | time=2.34s
```

### –¢–µ—Å—Ç 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ fallback

```bash
# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Ollama proxy –Ω–∞ Mac
launchctl unload ~/Library/LaunchAgents/com.astrobot.ollama-proxy.plist

# –°–¥–µ–ª–∞—Ç—å —Ç–æ—Ç –∂–µ –∑–∞–ø—Ä–æ—Å
curl http://localhost:8000/v1/tarot/draw -X POST ...

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏
docker compose logs api | grep LLM
```

–î–æ–ª–∂–Ω—ã —É–≤–∏–¥–µ—Ç—å:
```
LLM request | provider=auto (ollama‚Üíopenrouter‚Üígemini)
Ollama failed, trying OpenRouter fallback...
LLM success | provider=openrouter (fallback) | time=3.12s
```

**‚úÖ –ï—Å–ª–∏ –≤–∏–¥–∏—Ç–µ "provider=openrouter (fallback)" - –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç!**

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å proxy —Å–Ω–æ–≤–∞
launchctl load ~/Library/LaunchAgents/com.astrobot.ollama-proxy.plist
```

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤:

```bash
# 1. Ollama proxy –Ω–∞ Mac
curl http://localhost:8888/health

# 2. Ollama —á–µ—Ä–µ–∑ Tailscale
curl https://your-macbook.tail1234.ts.net/health

# 3. Backend health
curl http://localhost:8000/health

# 4. Tailscale —Å—Ç–∞—Ç—É—Å
tailscale status
tailscale funnel status
```

### –õ–æ–≥–∏:

```bash
# Proxy –ª–æ–≥–∏ (–Ω–∞ Mac)
tail -f ~/ollama-proxy/proxy.log

# Backend –ª–æ–≥–∏
docker compose logs -f api | grep LLM

# –§–∏–ª—å—Ç—Ä —Ç–æ–ª—å–∫–æ fallback —Å–æ–±—ã—Ç–∏–π
docker compose logs -f api | grep "fallback"
```

---

## üîß Troubleshooting

### Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ —á–µ—Ä–µ–∑ Tailscale

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ proxy –∑–∞–ø—É—â–µ–Ω
ps aux | grep "python.*main.py"

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ Funnel –∞–∫—Ç–∏–≤–µ–Ω
tailscale funnel status

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å funnel
tailscale funnel off
tailscale funnel 8888

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å firewall (–µ—Å–ª–∏ macOS –±–ª–æ–∫–∏—Ä—É–µ—Ç)
sudo /usr/libexec/ApplicationFirewall/socketfilterfw --add /usr/local/bin/python3
```

### Backend –Ω–µ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ fallback

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å .env
grep -E "(LLM_PROVIDER|OLLAMA_TIMEOUT|OPENROUTER_API_KEY)" .env

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –∫–ª—é—á–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã
echo $OPENROUTER_API_KEY  # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ –ø—É—Å—Ç—ã–º

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å backend
docker compose restart api
```

### OpenRouter –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫—É

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å privacy settings
# https://openrouter.ai/settings/privacy
# –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤–∫–ª—é—á–µ–Ω–æ: "Allow free models"

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–∏–º–∏—Ç—ã
curl https://openrouter.ai/api/v1/auth/key \
  -H "Authorization: Bearer $OPENROUTER_API_KEY"
```

---

## üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

–ü–æ—Å–ª–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤—ã –º–æ–∂–µ—Ç–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –∫–∞–∫–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:

```bash
# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –∫–∞–∂–¥–æ–º—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
docker compose logs api --since 1h | grep "LLM success" | \
  sed -E 's/.*provider=([^ ]+).*/\1/' | sort | uniq -c

# –ü—Ä–∏–º–µ—Ä –≤—ã–≤–æ–¥–∞:
#  45 ollama              # 45 –∑–∞–ø—Ä–æ—Å–æ–≤ —á–µ—Ä–µ–∑ Mac
#   3 openrouter (fallback)  # 3 —Ä–∞–∑–∞ —É–ø–∞–ª Mac
#   1 gemini (fallback)      # 1 —Ä–∞–∑ —É–ø–∞–ª–∏ –æ–±–∞
```

---

## ‚úÖ –ì–æ—Ç–æ–≤–æ!

–¢–µ–ø–µ—Ä—å —É –≤–∞—Å:
- ‚úÖ –°—Ç–∞–±–∏–ª—å–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ Ollama —á–µ—Ä–µ–∑ Tailscale
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π fallback –Ω–∞ OpenRouter/Gemini
- ‚úÖ –ü–æ–¥—Ä–æ–±–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è debugging
- ‚úÖ –ê–≤—Ç–æ–∑–∞–ø—É—Å–∫ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ Mac

**–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**
1. –ó–∞–¥–µ–ø–ª–æ–∏—Ç—å –Ω–∞ Render —Å —ç—Ç–∏–º–∏ –∂–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
2. –î–æ–±–∞–≤–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
3. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å alerts –ø—Ä–∏ —á–∞—Å—Ç—ã—Ö fallback (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

–ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤ [ollama-proxy/README.md](ollama-proxy/README.md)
